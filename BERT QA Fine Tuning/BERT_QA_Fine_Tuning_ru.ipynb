{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Q&A with BERT-Finetuned"],"metadata":{"id":"fhZy9p42zjDd"}},{"cell_type":"markdown","source":["Мы проведем дообучение BERT-модели на датасете [SQuAD1.0](https://rajpurkar.github.io/SQuAD-explorer/), состоящем из вопросов, заданных краудворкерами по набору статей Википедии.\n","\n","Модели, основанные только на энкодере, такие как BERT, как правило, отлично справляются с извлечением ответов на фактоидные вопросы типа \"Кто изобрел архитектуру трансформера?\", но плохо справляются с открытыми вопросами типа \"Почему небо голубое?\". В таких сложных случаях для синтеза информации обычно используются модели энкодеров-декодеров, такие как T5 и BART"],"metadata":{"id":"TPKWDGUVz0B5"}},{"cell_type":"markdown","source":["## Установка библиотек"],"metadata":{"id":"sB2EejiG09Dd"}},{"cell_type":"code","source":["!pip install --upgrade datasets fsspec"],"metadata":{"id":"_7w1i0gnWjP8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install datasets evaluate transformers[sentencepiece]\n","!pip install accelerate\n","# To run the training on TPU, you will need to uncomment the following line:\n","# !pip install cloud-tpu-client==0.10 torch==1.9.0 https://storage.googleapis.com/tpu-pytorch/wheels/torch_xla-1.9-cp37-cp37m-linux_x86_64.whl\n","!apt install git-lfs"],"metadata":{"id":"FCZnaeNXWiS4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email \"your_email\"\n","!git config --global user.name \"your_username\""],"metadata":{"id":"OdMIx85_SEU2","executionInfo":{"status":"ok","timestamp":1751345915121,"user_tz":-420,"elapsed":196,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Импорт библиотек и модулей"],"metadata":{"id":"tSkh5DBP0cNN"}},{"cell_type":"code","source":["from datasets import load_dataset\n","from huggingface_hub import notebook_login\n","from transformers import AutoTokenizer\n","import torch\n","from transformers import AutoModelForQuestionAnswering\n","import collections\n","import tensorflow as tf\n","from transformers import TFAutoModelForQuestionAnswering\n","import numpy as np\n","import evaluate\n","from tqdm.auto import tqdm\n","from transformers import TrainingArguments\n","from transformers import Trainer\n","from accelerate import Accelerator\n","from torch.utils.data import DataLoader\n","from transformers import default_data_collator\n","from torch.optim import AdamW\n","from transformers import get_scheduler\n","from huggingface_hub import Repository, get_full_repo_name\n","from transformers import pipeline"],"metadata":{"id":"FKEGt6X7WgMG"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Авторизация в HuggingFace"],"metadata":{"id":"BNH6cga_6IrI"}},{"cell_type":"code","source":["notebook_login()"],"metadata":{"id":"wIjrXrFj1GoX","executionInfo":{"status":"aborted","timestamp":1751345917305,"user_tz":-420,"elapsed":1,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Загрузка и анализ датасета SQuAD"],"metadata":{"id":"WP959Dx20MFe"}},{"cell_type":"code","source":["raw_datasets = load_dataset(\"squad\")"],"metadata":{"id":"xAdvJlMscuzl","executionInfo":{"status":"aborted","timestamp":1751345917319,"user_tz":-420,"elapsed":13,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QdnTJbHwyNVb","executionInfo":{"status":"aborted","timestamp":1751345917332,"user_tz":-420,"elapsed":115208,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"outputs":[],"source":["raw_datasets"]},{"cell_type":"markdown","source":["Похоже, у нас есть все необходимое в полях context, question и answers, так что давайте выведем их для первого элемента нашего обучающего набора:"],"metadata":{"id":"iLWEh6s30ny5"}},{"cell_type":"code","source":["print(\"Context: \", raw_datasets[\"train\"][0][\"context\"])\n","print(\"Question: \", raw_datasets[\"train\"][0][\"question\"])\n","print(\"Answer: \", raw_datasets[\"train\"][0][\"answers\"])"],"metadata":{"id":"AAJMHmdF0oMF","executionInfo":{"status":"aborted","timestamp":1751345917333,"user_tz":-420,"elapsed":115206,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Поля context и question очень просты в использовании. С полем answers немного сложнее, поскольку оно представляет собой словарь с двумя полями, которые оба являются списками. Именно такой формат будет ожидать метрика squad при оценке. Поле text довольно очевидно, а поле answer_start содержит индекс начального символа каждого ответа в контексте.\n","\n","Во время обучения существует только один возможный ответ. Мы можем перепроверить это с помощью метода Dataset.filter():"],"metadata":{"id":"7UCwId3F1Xhd"}},{"cell_type":"code","source":["raw_datasets[\"train\"].filter(lambda x: len(x[\"answers\"][\"text\"]) != 1)"],"metadata":{"id":"Cs_zdxLdcy9I","executionInfo":{"status":"aborted","timestamp":1751345917334,"user_tz":-420,"elapsed":115207,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Для оценки, однако, существует несколько возможных ответов для каждого примера, которые могут быть одинаковыми или разными:"],"metadata":{"id":"UrYWhIvK1ht5"}},{"cell_type":"code","source":["print(raw_datasets[\"validation\"][0][\"answers\"])\n","print(raw_datasets[\"validation\"][2][\"answers\"])"],"metadata":{"id":"_t7TMGpB1jNW","executionInfo":{"status":"aborted","timestamp":1751345917335,"user_tz":-420,"elapsed":115205,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" Суть в том, что некоторые вопросы имеют несколько возможных ответов, и этот сценарий будет сравнивать спрогнозированный ответ со всеми допустимыми ответами и выбирать лучший результат. Если мы посмотрим, например, на выборку с индексом 2:"],"metadata":{"id":"gLW1OnQN1obV"}},{"cell_type":"code","source":["print(raw_datasets[\"validation\"][2][\"context\"])\n","print(raw_datasets[\"validation\"][2][\"question\"])"],"metadata":{"id":"DLuSmciw1ptp","executionInfo":{"status":"aborted","timestamp":1751345917335,"user_tz":-420,"elapsed":115203,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ответ действительно может быть одним из трех возможных вариантов, которые мы видели ранее."],"metadata":{"id":"boQ_BjUD1tAl"}},{"cell_type":"markdown","source":["## Подготовка обучающих данных"],"metadata":{"id":"nDSS98zb1u5y"}},{"cell_type":"markdown","source":["Сначала нам нужно преобразовать текст во входных данных в идентификаторы, которые модель сможет понять, используя токенизатор:"],"metadata":{"id":"iu_NZliy12gx"}},{"cell_type":"code","source":["model_checkpoint = \"bert-base-cased\"\n","tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"metadata":{"id":"B4m78y2nc00o","executionInfo":{"status":"aborted","timestamp":1751345917336,"user_tz":-420,"elapsed":115204,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Чтобы проверить, что используемый объект tokenizer действительно поддерживается используется его атрибут is_fast:"],"metadata":{"id":"xNjkfEaD1_gV"}},{"cell_type":"code","source":["tokenizer.is_fast"],"metadata":{"id":"XzaasCOL1_Ep","executionInfo":{"status":"aborted","timestamp":1751345917337,"user_tz":-420,"elapsed":115203,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Мы можем передать нашему токенизатору вопрос и контекст вместе, и он правильно вставит специальные токены, чтобы сформировать предложение, подобное этому:"],"metadata":{"id":"cD6dT6SK2G8a"}},{"cell_type":"code","source":["context = raw_datasets[\"train\"][0][\"context\"]\n","question = raw_datasets[\"train\"][0][\"question\"]\n","\n","inputs = tokenizer(question, context)\n","tokenizer.decode(inputs[\"input_ids\"])"],"metadata":{"id":"ORw-ragU2GZ1","executionInfo":{"status":"aborted","timestamp":1751345917345,"user_tz":-420,"elapsed":115208,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["В данном случае контекст не слишком длинный, но некоторые примеры в датасете имеют очень длинные контексты, которые превысят установленную нами максимальную длину (которая в данном случае равна 384).\n","\n","Чтобы увидеть, как это работает на текущем примере, мы можем ограничить длину до 100 и использовать скользящее окно из 50 токенов. Используем:\n","* max_length (возьмем 100)\n","* truncation=\"only_second\" для усечения контекста (который находится во второй позиции), когда вопрос с его контекстом слишком длинный\n","* stride для задания количества перекрывающихся токенов между двумя последовательными фрагментами (возьмем 50)\n","* return_overflowing_tokens=True, чтобы сообщить токенизатору, что нам нужны переполненные токены (overflowing tokens)"],"metadata":{"id":"Hauze8Ae2aNF"}},{"cell_type":"code","source":["inputs = tokenizer(\n","    question,\n","    context,\n","    max_length=100,\n","    truncation=\"only_second\",\n","    stride=50,\n","    return_overflowing_tokens=True,\n",")\n","\n","for ids in inputs[\"input_ids\"]:\n","    print(tokenizer.decode(ids))"],"metadata":{"id":"6PDOPD762May","executionInfo":{"status":"aborted","timestamp":1751345917361,"user_tz":-420,"elapsed":115220,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Как мы можем видеть, наш пример был разбит на четыре входа, каждый из которых содержит вопрос и часть контекста. Ответ на вопрос (\"Bernadette Soubirous\") появляется только в третьем и последнем входе, поэтому, работая с длинными контекстами таким образом, мы создадим несколько обучающих примеров, в которых ответ не будет включен в контекст. Для этих примеров метками будут start_position = end_position = 0 (таким образом мы предсказываем токен [CLS]). Мы также зададим эти метки в неудачном случае, когда ответ был усечен, так что у нас есть только его начало (или конец). Для примеров, где ответ полностью находится в контексте, метками будут индекс токена, с которого начинается ответ, и индекс токена, на котором ответ заканчивается.\n","\n","Датасет предоставляет нам начальный символ ответа в контексте, а прибавив к нему длину ответа, мы можем найти конечный символ в контексте. Чтобы сопоставить их с индексами токенов, нам нужно использовать сопоставление смещений6. Мы можем настроить наш токенизатор на их возврат, передав return_offsets_mapping=True:"],"metadata":{"id":"7aB1yEMp2qut"}},{"cell_type":"code","source":["inputs = tokenizer(\n","    question,\n","    context,\n","    max_length=100,\n","    truncation=\"only_second\",\n","    stride=50,\n","    return_overflowing_tokens=True,\n","    return_offsets_mapping=True,\n",")\n","inputs.keys()"],"metadata":{"id":"F4trBIN623uK","executionInfo":{"status":"aborted","timestamp":1751345917362,"user_tz":-420,"elapsed":115219,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Как мы видим, нам возвращаются обычные идентификаторы входа, идентификаторы типов токенов и маска внимания, а также необходимое нам сопоставление смещений и дополнительный ключ overflow_to_sample_mapping. Соответствующее значение мы будем использовать при токенизации нескольких текстов одновременно (что мы и должны делать, чтобы извлечь выгоду из того, что наш токенизатор основан на Rust). Поскольку один образец может давать несколько признаков, он сопоставляет каждый признак с примером, из которого он произошел. Поскольку здесь мы токенизировали только один пример, мы получим список 0:"],"metadata":{"id":"0itGTQOk26gZ"}},{"cell_type":"code","source":["inputs[\"overflow_to_sample_mapping\"]"],"metadata":{"id":"BfcL1pl12--R","executionInfo":{"status":"aborted","timestamp":1751345917363,"user_tz":-420,"elapsed":115218,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Но если мы проведем токенизацию большего количества примеров, он станет эффективнее:"],"metadata":{"id":"rPjVf94O3Ats"}},{"cell_type":"code","source":["inputs = tokenizer(\n","    raw_datasets[\"train\"][2:6][\"question\"],\n","    raw_datasets[\"train\"][2:6][\"context\"],\n","    max_length=100,\n","    truncation=\"only_second\",\n","    stride=50,\n","    return_overflowing_tokens=True,\n","    return_offsets_mapping=True,\n",")\n","\n","print(f\"The 4 examples gave {len(inputs['input_ids'])} features.\")\n","print(f\"Here is where each comes from: {inputs['overflow_to_sample_mapping']}.\")"],"metadata":{"id":"PqEN52yA26Jd","executionInfo":{"status":"aborted","timestamp":1751345917364,"user_tz":-420,"elapsed":115217,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Как мы видим, первые три примера (с индексами 2, 3 и 4 в обучающем наборе) дали по четыре признака, а последний пример (с индексом 5 в обучающем наборе) - 7 признаков."],"metadata":{"id":"YPQBZABU3GzN"}},{"cell_type":"markdown","source":["Эта информация будет полезна для сопоставления каждого полученного признака с соответствующей меткой. Этими метками являются:\n","\n","* (0, 0), если ответ не находится в соответствующей области контекста\n","* (start_position, end_position), если ответ находится в соответствующей области контекста, причем start_position - это индекс токена (во входных идентификаторах) в начале ответа, а end_position - индекс токена (во входных идентификаторах) в конце ответа"],"metadata":{"id":"_QWslWhH3JDu"}},{"cell_type":"markdown","source":["Чтобы определить, какой из этих случаев имеет место, и, если нужно, позиции токенов, мы сначала находим индексы, с которых начинается и заканчивается контекст во входных идентификаторах. Для этого мы могли бы использовать идентификаторы типов токенов, но поскольку они не обязательно существуют для всех моделей (например, DistilBERT их не требует), вместо этого мы воспользуемся методом sequence_ids() из BatchEncoding, который возвращает наш токенизатор."],"metadata":{"id":"TUWMzcwN3NRK"}},{"cell_type":"markdown","source":["Получив индексы токенов, мы смотрим на соответствующие смещения, которые представляют собой кортежи из двух целых чисел, обозначающих промежуток символов внутри исходного контекста. Таким образом, мы можем определить, начинается ли фрагмент контекста в этом признаке после ответа или заканчивается до начала ответа (в этом случае метка будет (0, 0)). Если это не так, мы зацикливаемся, чтобы найти первый и последний токен ответа:"],"metadata":{"id":"dqGY9NlK3Q8t"}},{"cell_type":"code","source":["answers = raw_datasets[\"train\"][2:6][\"answers\"]\n","start_positions = []\n","end_positions = []\n","\n","for i, offset in enumerate(inputs[\"offset_mapping\"]):\n","    sample_idx = inputs[\"overflow_to_sample_mapping\"][i]\n","    answer = answers[sample_idx]\n","    start_char = answer[\"answer_start\"][0]\n","    end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n","    sequence_ids = inputs.sequence_ids(i)\n","\n","    # Найдём начало и конец контекста\n","    idx = 0\n","    while sequence_ids[idx] != 1:\n","        idx += 1\n","    context_start = idx\n","    while sequence_ids[idx] == 1:\n","        idx += 1\n","    context_end = idx - 1\n","\n","    # Если ответ не полностью находится внутри контекста, меткой будет (0, 0)\n","    if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n","        start_positions.append(0)\n","        end_positions.append(0)\n","    else:\n","        # В противном случае это начальная и конечная позиции токенов\n","        idx = context_start\n","        while idx <= context_end and offset[idx][0] <= start_char:\n","            idx += 1\n","        start_positions.append(idx - 1)\n","\n","        idx = context_end\n","        while idx >= context_start and offset[idx][1] >= end_char:\n","            idx -= 1\n","        end_positions.append(idx + 1)\n","\n","start_positions, end_positions"],"metadata":{"id":"GHBSBIVU3UYl","executionInfo":{"status":"aborted","timestamp":1751345917371,"user_tz":-420,"elapsed":115222,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Давайте посмотрим на несколько результатов, чтобы убедиться в правильности нашего подхода. Для первого признака мы находим (83, 85) в качестве меток, поэтому давайте сравним теоретический ответ с декодированным диапазоном лексем с 83 по 85 (включительно):"],"metadata":{"id":"KtGR5aD13kEV"}},{"cell_type":"code","source":["idx = 0\n","sample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\n","answer = answers[sample_idx][\"text\"][0]\n","\n","start = start_positions[idx]\n","end = end_positions[idx]\n","labeled_answer = tokenizer.decode(inputs[\"input_ids\"][idx][start : end + 1])\n","\n","print(f\"Theoretical answer: {answer}, labels give: {labeled_answer}\")"],"metadata":{"id":"Lr_qajx23kap","executionInfo":{"status":"aborted","timestamp":1751345917372,"user_tz":-420,"elapsed":115221,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Итак, это совпадение! Теперь проверим индекс 4, где мы установили метки на (0, 0), что означает, что ответ не находится в фрагменте контекста этого признака:"],"metadata":{"id":"ki-BUB9e3n-6"}},{"cell_type":"code","source":["idx = 4\n","sample_idx = inputs[\"overflow_to_sample_mapping\"][idx]\n","answer = answers[sample_idx][\"text\"][0]\n","\n","decoded_example = tokenizer.decode(inputs[\"input_ids\"][idx])\n","print(f\"Theoretical answer: {answer}, decoded example: {decoded_example}\")"],"metadata":{"id":"m0qNuLw_3oMg","executionInfo":{"status":"aborted","timestamp":1751345917373,"user_tz":-420,"elapsed":115220,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Нет ответа в контексте."],"metadata":{"id":"FLivZQYS3qjG"}},{"cell_type":"markdown","source":["Теперь, когда мы шаг за шагом разобрались с предварительной обработкой обучающих данных, мы можем сгруппировать их в функцию, которую будем применять ко всему датасету. Мы дополним каждый признак до максимальной длины, которую мы задали, поскольку большинство контекстов будут длинными (и соответствующие образцы будут разбиты на несколько признаков), поэтому применение динамического дополнения здесь не имеет реальной пользы:"],"metadata":{"id":"4dNk5KGa3s0J"}},{"cell_type":"code","source":["max_length = 384\n","stride = 128\n","\n","\n","def preprocess_training_examples(examples):\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    inputs = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        max_length=max_length,\n","        truncation=\"only_second\",\n","        stride=stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    offset_mapping = inputs.pop(\"offset_mapping\")\n","    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n","    answers = examples[\"answers\"]\n","    start_positions = []\n","    end_positions = []\n","\n","    for i, offset in enumerate(offset_mapping):\n","        sample_idx = sample_map[i]\n","        answer = answers[sample_idx]\n","        start_char = answer[\"answer_start\"][0]\n","        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n","        sequence_ids = inputs.sequence_ids(i)\n","\n","        # Найдём начало и конец контекста\n","        idx = 0\n","        while sequence_ids[idx] != 1:\n","            idx += 1\n","        context_start = idx\n","        while sequence_ids[idx] == 1:\n","            idx += 1\n","        context_end = idx - 1\n","\n","        # Если ответ не полностью находится внутри контекста, меткой будет (0, 0)\n","        if offset[context_start][0] > start_char or offset[context_end][1] < end_char:\n","            start_positions.append(0)\n","            end_positions.append(0)\n","        else:\n","            # В противном случае это начальная и конечная позиции токенов\n","            idx = context_start\n","            while idx <= context_end and offset[idx][0] <= start_char:\n","                idx += 1\n","            start_positions.append(idx - 1)\n","\n","            idx = context_end\n","            while idx >= context_start and offset[idx][1] >= end_char:\n","                idx -= 1\n","            end_positions.append(idx + 1)\n","\n","    inputs[\"start_positions\"] = start_positions\n","    inputs[\"end_positions\"] = end_positions\n","    return inputs"],"metadata":{"id":"P36Vdot83zTt","executionInfo":{"status":"aborted","timestamp":1751345917374,"user_tz":-420,"elapsed":115221,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Обратите внимание, что мы определили две константы для определения максимальной длины и длины скользящего окна, а также добавили немного очистки перед токенизацией: некоторые вопросы в датасете SQuAD имеют лишние пробелы в начале и конце, которые ничего не добавляют, поэтому мы удалили эти лишние пробелы."],"metadata":{"id":"APkw0apl37Xi"}},{"cell_type":"markdown","source":["Чтобы применить эту функцию ко всему обучающему набору, мы используем метод Dataset.map() с флагом batched=True. Это необходимо, так как мы изменяем длину датасета (поскольку один пример может давать несколько обучающих признаков):"],"metadata":{"id":"EP8O0_Ne4BNr"}},{"cell_type":"code","source":["train_dataset = raw_datasets[\"train\"].map(\n","    preprocess_training_examples,\n","    batched=True,\n","    remove_columns=raw_datasets[\"train\"].column_names,\n",")\n","len(raw_datasets[\"train\"]), len(train_dataset)"],"metadata":{"id":"UOvTj3WOc2wH","executionInfo":{"status":"aborted","timestamp":1751345917455,"user_tz":-420,"elapsed":115302,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Как мы видим, предварительная обработка добавила около 1 000 признаков. Теперь наш обучающий набор готов к использованию. Перейдем к предварительной обработке валидационного набора."],"metadata":{"id":"l9hjEAeR4NUZ"}},{"cell_type":"markdown","source":["## Подготовка валидационных данных"],"metadata":{"id":"Si21dj_U4MeJ"}},{"cell_type":"markdown","source":["Предварительная обработка валидационных данных будет немного проще, поскольку нам не нужно генерировать метки. Настоящей радостью будет интерпретация прогнозов модели в диапазонах исходного контекста. Для этого нам нужно хранить как сопоставления смещений, так и способ сопоставления каждого созданного признака с оригинальным примером, из которого он взят. Поскольку в исходном датасете есть столбец ID, мы будем использовать этот ID."],"metadata":{"id":"Tgt5tHXT4UAt"}},{"cell_type":"markdown","source":["Нужно очистить сопоставления смещений. Они будут содержать смещения для вопроса и контекста, но на этапе постобработки у нас не будет возможности узнать, какая часть входных идентификаторов соответствует контексту, а какая - вопросу (метод sequence_ids(), который мы использовали, доступен только для выхода токенизатора). Поэтому мы установим смещения, соответствующие вопросу, в None:"],"metadata":{"id":"T3NBhOeV4bOm"}},{"cell_type":"code","source":["def preprocess_validation_examples(examples):\n","    questions = [q.strip() for q in examples[\"question\"]]\n","    inputs = tokenizer(\n","        questions,\n","        examples[\"context\"],\n","        max_length=max_length,\n","        truncation=\"only_second\",\n","        stride=stride,\n","        return_overflowing_tokens=True,\n","        return_offsets_mapping=True,\n","        padding=\"max_length\",\n","    )\n","\n","    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n","    example_ids = []\n","\n","    for i in range(len(inputs[\"input_ids\"])):\n","        sample_idx = sample_map[i]\n","        example_ids.append(examples[\"id\"][sample_idx])\n","\n","        sequence_ids = inputs.sequence_ids(i)\n","        offset = inputs[\"offset_mapping\"][i]\n","        inputs[\"offset_mapping\"][i] = [\n","            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n","        ]\n","\n","    inputs[\"example_id\"] = example_ids\n","    return inputs"],"metadata":{"id":"2QK64rl94ioi","executionInfo":{"status":"aborted","timestamp":1751345917457,"user_tz":-420,"elapsed":115303,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["validation_dataset = raw_datasets[\"validation\"].map(\n","    preprocess_validation_examples,\n","    batched=True,\n","    remove_columns=raw_datasets[\"validation\"].column_names,\n",")\n","len(raw_datasets[\"validation\"]), len(validation_dataset)"],"metadata":{"id":"OH2I-tjuc4EP","executionInfo":{"status":"aborted","timestamp":1751345917459,"user_tz":-420,"elapsed":115305,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["В данном случае мы добавили всего пару сотен примеров, поэтому контексты в валидационном датасете немного короче.\n","\n","Теперь, когда мы предварительно обработали все данные, можно приступать к обучению."],"metadata":{"id":"IaGoFTvT4p3-"}},{"cell_type":"markdown","source":["## Fine-Tuning модели"],"metadata":{"id":"j07nDkmK4sm6"}},{"cell_type":"markdown","source":["### Постобработка"],"metadata":{"id":"JSe8RxYW5Rfe"}},{"cell_type":"markdown","source":["Модель выведет логиты для начальной и конечной позиций ответа во входных идентификаторах.\n","\n","Чтобы ускорить процесс, мы также не будем оценивать все возможные пары (start_token, end_token), а только те, которые соответствуют наибольшим n_best логитам (при n_best=20). Так как мы пропустим softmax, эти оценки будут оценками логитов, и будут получены путем взятия суммы начального и конечного логитов (вместо произведения, по правилу \\(\\log(ab) = \\log(a) + \\log(b)\\)).\n","\n","Чтобы продемонстрировать все это, нам понадобятся некоторые прогнозы. Поскольку мы еще не обучили нашу модель, мы будем использовать модель по умолчанию для конвейера QA, чтобы сгенерировать несколько прогнозов на небольшой части набора для валидации. Мы можем использовать ту же функцию обработки, что и раньше; поскольку она опирается на глобальную константу tokenizer, нам просто нужно изменить этот объект на токенизатор модели, которую мы хотим временно использовать:"],"metadata":{"id":"k4G-XhEj5i2W"}},{"cell_type":"code","source":["small_eval_set = raw_datasets[\"validation\"].select(range(100))\n","trained_checkpoint = \"distilbert-base-cased-distilled-squad\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n","eval_set = small_eval_set.map(\n","    preprocess_validation_examples,\n","    batched=True,\n","    remove_columns=raw_datasets[\"validation\"].column_names,\n",")"],"metadata":{"id":"owN4mySLc5AE","executionInfo":{"status":"aborted","timestamp":1751345917460,"user_tz":-420,"elapsed":115306,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Теперь, когда препроцессинг завершен, мы меняем токенизатор обратно на тот, который был выбран изначально:"],"metadata":{"id":"QJQW04Sw5wyB"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"],"metadata":{"id":"2h_P5XHF5yLB","executionInfo":{"status":"aborted","timestamp":1751345917471,"user_tz":-420,"elapsed":115317,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Затем мы удаляем из нашего eval_set столбцы, которые не ожидает модель, создаем батч со всей этой небольшой валидацией и пропускаем его через модель."],"metadata":{"id":"DM9yEn945zmO"}},{"cell_type":"code","source":["eval_set_for_model = eval_set.remove_columns([\"example_id\", \"offset_mapping\"])\n","eval_set_for_model.set_format(\"torch\")\n","\n","device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","batch = {k: eval_set_for_model[k].to(device) for k in eval_set_for_model.column_names}\n","trained_model = AutoModelForQuestionAnswering.from_pretrained(trained_checkpoint).to(\n","    device\n",")\n","\n","with torch.no_grad():\n","    outputs = trained_model(**batch)"],"metadata":{"id":"7Yd67cRVc6Hv","executionInfo":{"status":"aborted","timestamp":1751345917476,"user_tz":-420,"elapsed":115322,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Поскольку Trainer будет возвращать нам прогнозы в виде массивов NumPy, мы берем начальный и конечный логиты и конвертируем их в этот формат:"],"metadata":{"id":"0nybj5dx6Am6"}},{"cell_type":"code","source":["start_logits = outputs.start_logits.cpu().numpy()\n","end_logits = outputs.end_logits.cpu().numpy()"],"metadata":{"id":"q3i3zidA6BFl","executionInfo":{"status":"aborted","timestamp":1751345917477,"user_tz":-420,"elapsed":115323,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Теперь нам нужно найти спрогнозированный ответ для каждого примера в small_eval_set. Один пример может быть разбит на несколько признаков в eval_set, поэтому первым шагом будет сопоставление каждого примера в small_eval_set с соответствующими признаками в eval_set:"],"metadata":{"id":"zOrGf_HC6Qjt"}},{"cell_type":"code","source":["example_to_features = collections.defaultdict(list)\n","for idx, feature in enumerate(eval_set):\n","    example_to_features[feature[\"example_id\"]].append(idx)"],"metadata":{"id":"mPY_asgN6SdR","executionInfo":{"status":"aborted","timestamp":1751345917478,"user_tz":-420,"elapsed":115324,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Имея это на руках, мы можем приступить к работе, итерируясь по всем примерам и, для каждого примера, по всем ассоциированным с ним признакам. Как мы уже говорили, мы рассмотрим оценки логитов для n_best начальных логитов и конечных логитов, исключая позиции, которые дают:\n","\n","Ответ, который не вписывается в контекст\n","Ответ с отрицательной длиной\n","Слишком длинный ответ (мы ограничиваем возможности по max_answer_length=30).\n","После того как мы получили все возможные ответы для одного примера, мы просто выбираем тот, который имеет лучшую оценку логита:"],"metadata":{"id":"FCmkNCP37lI-"}},{"cell_type":"code","source":["n_best = 20\n","max_answer_length = 30\n","predicted_answers = []\n","\n","for example in small_eval_set:\n","    example_id = example[\"id\"]\n","    context = example[\"context\"]\n","    answers = []\n","\n","    for feature_index in example_to_features[example_id]:\n","        start_logit = start_logits[feature_index]\n","        end_logit = end_logits[feature_index]\n","        offsets = eval_set[\"offset_mapping\"][feature_index]\n","\n","        start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n","        end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n","        for start_index in start_indexes:\n","            for end_index in end_indexes:\n","                # Пропускаем ответы, которые не полностью соответствуют контексту\n","                if offsets[start_index] is None or offsets[end_index] is None:\n","                    continue\n","                # Пропускайте ответы, длина которых либо < 0, либо > max_answer_length.\n","                if (\n","                    end_index < start_index\n","                    or end_index - start_index + 1 > max_answer_length\n","                ):\n","                    continue\n","\n","                answers.append(\n","                    {\n","                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n","                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n","                    }\n","                )\n","\n","    best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n","    predicted_answers.append({\"id\": example_id, \"prediction_text\": best_answer[\"text\"]})"],"metadata":{"id":"Y4hhUWkl7l-i","executionInfo":{"status":"aborted","timestamp":1751345917483,"user_tz":-420,"elapsed":115328,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Окончательный формат спрогнозированных ответов - это тот, который ожидает метрика, которую мы будем использовать. Как обычно, мы можем загрузить ее с помощью библиотеки Evaluate:"],"metadata":{"id":"hKk_RN9m77Ru"}},{"cell_type":"code","source":["metric = evaluate.load(\"squad\")"],"metadata":{"id":"qqM_675oc7o3","executionInfo":{"status":"aborted","timestamp":1751345917484,"user_tz":-420,"elapsed":115329,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Эта метрика ожидает прогнозируемые ответы в формате, который мы видели выше (список словарей с одним ключом для идентификатора примера и одним ключом для прогнозируемого текста), и теоретические ответы в формате ниже (список словарей с одним ключом для идентификатора примера и одним ключом для возможных ответов):"],"metadata":{"id":"8t2cgtu07-r-"}},{"cell_type":"code","source":["theoretical_answers = [\n","    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in small_eval_set\n","]"],"metadata":{"id":"AZMSmRme7--q","executionInfo":{"status":"aborted","timestamp":1751345917485,"user_tz":-420,"elapsed":115330,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Теперь мы можем убедиться, что получаем разумные результаты, посмотрев на первый элемент обоих списков:"],"metadata":{"id":"uTGubktr8BdU"}},{"cell_type":"code","source":["print(predicted_answers[0])\n","print(theoretical_answers[0])"],"metadata":{"id":"yTmxZv8d8CR2","executionInfo":{"status":"aborted","timestamp":1751345917507,"user_tz":-420,"elapsed":115350,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Не так уж плохо! Теперь давайте посмотрим на оценку, которую дает нам метрика:"],"metadata":{"id":"ML8hs8tW8Dw2"}},{"cell_type":"code","source":["metric.compute(predictions=predicted_answers, references=theoretical_answers)"],"metadata":{"id":"u8YxIbNS8EL2","executionInfo":{"status":"aborted","timestamp":1751345917508,"user_tz":-420,"elapsed":115350,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Теперь давайте поместим все, что мы только что сделали, в функцию compute_metrics(), которую мы будем использовать в Trainer. Обычно функция compute_metrics() получает только кортеж eval_preds с логитами и метками. Здесь нам понадобится немного больше, так как мы должны искать в датасете признаков смещения и в датасете примеров исходные контексты, поэтому мы не сможем использовать эту функцию для получения обычных результатов оценки во время обучения. Мы будем использовать ее только в конце обучения для проверки результатов.\n","\n","Функция compute_metrics() группирует те же шаги, что и до этого, только добавляется небольшая проверка на случай, если мы не найдем ни одного правильного ответа (в этом случае мы прогнозируем пустую строку)."],"metadata":{"id":"ig2aYgac8Rna"}},{"cell_type":"code","source":["def compute_metrics(start_logits, end_logits, features, examples):\n","    example_to_features = collections.defaultdict(list)\n","    for idx, feature in enumerate(features):\n","        example_to_features[feature[\"example_id\"]].append(idx)\n","\n","    predicted_answers = []\n","    for example in tqdm(examples):\n","        example_id = example[\"id\"]\n","        context = example[\"context\"]\n","        answers = []\n","\n","        # Итерируемся по всем признакам, ассоциированным с этим примером\n","        for feature_index in example_to_features[example_id]:\n","            start_logit = start_logits[feature_index]\n","            end_logit = end_logits[feature_index]\n","            offsets = features[feature_index][\"offset_mapping\"]\n","\n","            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n","            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n","            for start_index in start_indexes:\n","                for end_index in end_indexes:\n","                    # Пропускаем ответы, которые не полностью соответствуют контексту\n","                    if offsets[start_index] is None or offsets[end_index] is None:\n","                        continue\n","                    # Пропускайте ответы, длина которых либо < 0, либо > max_answer_length\n","                    if (\n","                        end_index < start_index\n","                        or end_index - start_index + 1 > max_answer_length\n","                    ):\n","                        continue\n","\n","                    answer = {\n","                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n","                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n","                    }\n","                    answers.append(answer)\n","\n","        # Выбираем ответ с лучшей оценкой\n","        if len(answers) > 0:\n","            best_answer = max(answers, key=lambda x: x[\"logit_score\"])\n","            predicted_answers.append(\n","                {\"id\": example_id, \"prediction_text\": best_answer[\"text\"]}\n","            )\n","        else:\n","            predicted_answers.append({\"id\": example_id, \"prediction_text\": \"\"})\n","\n","    theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n","    return metric.compute(predictions=predicted_answers, references=theoretical_answers)"],"metadata":{"id":"Mp9IeV9p8W62","executionInfo":{"status":"aborted","timestamp":1751345917509,"user_tz":-420,"elapsed":115350,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["compute_metrics(start_logits, end_logits, eval_set, small_eval_set)"],"metadata":{"id":"-nHI_ti7c9ZX","executionInfo":{"status":"aborted","timestamp":1751345917509,"user_tz":-420,"elapsed":115350,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Выглядит отлично! Теперь давайте используем это для дообучения нашей модели."],"metadata":{"id":"WXalrjNm8gZN"}},{"cell_type":"markdown","source":["### Дообучение модели"],"metadata":{"id":"i7A557My8hNW"}},{"cell_type":"markdown","source":["Теперь мы готовы к обучению нашей модели. Давайте сначала создадим ее, используя класс AutoModelForQuestionAnswering, как и раньше:"],"metadata":{"id":"npFiBjJ58l66"}},{"cell_type":"code","source":["model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"],"metadata":{"id":"dPbMR2Fqc-jV","executionInfo":{"status":"aborted","timestamp":1751345917510,"user_tz":-420,"elapsed":115351,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Как обычно, мы получаем предупреждение о том, что некоторые веса не используются (веса головы предварительного обучения), а другие инициализируются случайным образом (веса головы ответов на вопросы). Вы уже должны были привыкнуть к этому, но это означает, что модель еще не готова к использованию и нуждается в дообучении - хорошо, что мы сейчас этим займемся!"],"metadata":{"id":"SnGY-c2J8tJG"}},{"cell_type":"markdown","source":["Можем определить наши TrainingArguments. Как мы уже говорили, когда определяли нашу функцию для вычисления метрики, мы не сможем сделать обычный цикл оценки из-за сигнатуры функции compute_metrics(). Мы могли бы написать собственный подкласс Trainer для этого, но это слишком длинно для данного раздела. Вместо этого мы будем оценивать модель только в конце обучения, а как проводить регулярную оценку, покажем ниже в разделе \"Пользовательский цикл обучения\"."],"metadata":{"id":"jjLz31tI8yfK"}},{"cell_type":"code","source":["args = TrainingArguments(\n","    \"bert-finetuned-squad\",\n","    # evaluation_strategy=\"no\",\n","    save_strategy=\"epoch\",\n","    learning_rate=2e-5,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    fp16=True,\n","    push_to_hub=True,\n",")"],"metadata":{"id":"w5qbAL-r8tfC","executionInfo":{"status":"aborted","timestamp":1751345917510,"user_tz":-420,"elapsed":115351,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Наконец, мы просто передаем все в класс Trainer и запускаем обучение:"],"metadata":{"id":"vguKWDBp9s6B"}},{"cell_type":"code","source":["trainer = Trainer(\n","    model=model,\n","    args=args,\n","    train_dataset=train_dataset,\n","    eval_dataset=validation_dataset,\n","    tokenizer=tokenizer,\n",")\n","trainer.train()"],"metadata":{"id":"8avuk_eiewo6","executionInfo":{"status":"aborted","timestamp":1751345917532,"user_tz":-420,"elapsed":11,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Когда обучение завершено, мы можем наконец оценить нашу модель (и помолиться, что не потратили все это время вычислений впустую). Метод predict() функции Trainer вернет кортеж, где первыми элементами будут предсказания модели (здесь пара с начальным и конечным логитами). Мы отправляем его в нашу функцию compute_metrics():"],"metadata":{"id":"5u_2AwYJ-Lcr"}},{"cell_type":"code","source":["predictions, _, _ = trainer.predict(validation_dataset)\n","start_logits, end_logits = predictions\n","compute_metrics(start_logits, end_logits, validation_dataset, raw_datasets[\"validation\"])"],"metadata":{"id":"SfBXvCcjc_16","executionInfo":{"status":"aborted","timestamp":1751345917532,"user_tz":-420,"elapsed":9,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Отлично! Для сравнения, базовые показатели, указанные в статье BERT для этой модели, составляют 80,8 и 88,5, так что мы как раз там, где должны быть."],"metadata":{"id":"K2OgZAT1-S-7"}},{"cell_type":"markdown","source":["Наконец, мы используем метод push_to_hub(), чтобы убедиться, что мы загрузили последнюю версию модели:"],"metadata":{"id":"8siqvk_C-UG6"}},{"cell_type":"code","source":["trainer.push_to_hub(commit_message=\"Training complete\")"],"metadata":{"id":"Rejp4vj4UAlW","executionInfo":{"status":"aborted","timestamp":1751345917533,"user_tz":-420,"elapsed":9,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Это возвращает URL только что выполненного коммита."],"metadata":{"id":"Ovigua_w-XxS"}},{"cell_type":"markdown","source":["Trainer также создает черновик карточки модели со всеми результатами оценки и загружает ее."],"metadata":{"id":"_k7OvJlU-Ze8"}},{"cell_type":"markdown","source":["### Цикл обучения"],"metadata":{"id":"Zuf6ROL6-cCV"}},{"cell_type":"markdown","source":["Сначала нам нужно создать DataLoaderы из наших датасетов. Мы установим формат этих датасетов в \"torch\" и удалим столбцы в наборе валидации, которые не используются моделью. Затем мы можем использовать default_data_collator, предоставляемый Transformers, в качестве collate_fn и перемешаем обучающий набор, но не набор для валидации:"],"metadata":{"id":"flg_2BPo-kpZ"}},{"cell_type":"code","source":["train_dataset.set_format(\"torch\")\n","validation_set = validation_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\n","validation_set.set_format(\"torch\")\n","\n","train_dataloader = DataLoader(\n","    train_dataset,\n","    shuffle=True,\n","    collate_fn=default_data_collator,\n","    batch_size=8,\n",")\n","eval_dataloader = DataLoader(\n","    validation_set, collate_fn=default_data_collator, batch_size=8\n",")"],"metadata":{"id":"rRdVPiuY-lLV","executionInfo":{"status":"aborted","timestamp":1751345917534,"user_tz":-420,"elapsed":9,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Затем мы реинстанцируем нашу модель, чтобы убедиться, что мы не продолжаем дообучение, а снова начинаем с предварительно обученной модели BERT:"],"metadata":{"id":"6wBMiHfK-oQ2"}},{"cell_type":"code","source":["model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)"],"metadata":{"id":"0uJXgdrpU2HR","executionInfo":{"status":"aborted","timestamp":1751345917534,"user_tz":-420,"elapsed":3,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Тогда нам понадобится оптимизатор. Как обычно, мы используем классический AdamW, который похож на Adam, но с исправлением в способе применения затухания веса:"],"metadata":{"id":"wcK6m_sA-q6p"}},{"cell_type":"code","source":["optimizer = AdamW(model.parameters(), lr=2e-5)"],"metadata":{"id":"V4rzbotQ-rVC","executionInfo":{"status":"aborted","timestamp":1751345917535,"user_tz":-420,"elapsed":115375,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# accelerator = Accelerator(fp16=True)\n","accelerator = Accelerator(mixed_precision=\"fp16\")\n","model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n","    model, optimizer, train_dataloader, eval_dataloader\n",")"],"metadata":{"id":"kusRHiDD--Fz","executionInfo":{"status":"aborted","timestamp":1751345917536,"user_tz":-420,"elapsed":115376,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Мы можем использовать длину train_dataloader для вычисления количества шагов обучения только после того, как она пройдет через метод accelerator.prepare(). Мы используем тот же линейный график, что и в предыдущих разделах:"],"metadata":{"id":"FOeWxKKGBGRm"}},{"cell_type":"code","source":["num_train_epochs = 2\n","num_update_steps_per_epoch = len(train_dataloader)\n","num_training_steps = num_train_epochs * num_update_steps_per_epoch\n","\n","lr_scheduler = get_scheduler(\n","    \"linear\",\n","    optimizer=optimizer,\n","    num_warmup_steps=0,\n","    num_training_steps=num_training_steps,\n",")"],"metadata":{"id":"gxSXgJfWBHln","executionInfo":{"status":"aborted","timestamp":1751345917536,"user_tz":-420,"elapsed":115376,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Чтобы отправить нашу модель на Hub, нам нужно создать объект Repository в рабочей папке. Сначала войдите в Hub Hugging Face, если вы еще не вошли в него. Мы определим имя розитория по идентификатору модели, который мы хотим присвоить нашей модели (не стесняйтесь заменить repo_name на свое усмотрение; оно просто должно содержать ваше имя пользователя, что и делает функция get_full_repo_name()):"],"metadata":{"id":"ryPiO5HTBKQw"}},{"cell_type":"code","source":["model_name = \"bert-finetuned-squad-accelerate\"\n","repo_name = get_full_repo_name(model_name)\n","repo_name"],"metadata":{"id":"735_KZF2U4YW","executionInfo":{"status":"aborted","timestamp":1751345917537,"user_tz":-420,"elapsed":115377,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Код ниже вызовет ошибку \"Repo not found\". В сообществе HuggingFace найдено следующее решение проблемы:\n","* Перейдите к последней строке ошибки и найдите, какой репозиторий не найден.\n","* Перейдите на страницу [Hugging Face - The AI community building the future](https://huggingface.co/new), чтобы создать репозиторий, который отсутствует.\n","* Запустить код снова"],"metadata":{"id":"Pnvb-XDYgtKi"}},{"cell_type":"code","source":["output_dir = \"bert-finetuned-squad-accelerate\"\n","repo = Repository(output_dir, clone_from=repo_name)"],"metadata":{"id":"JTjWm8nOUDiX","executionInfo":{"status":"aborted","timestamp":1751345917537,"user_tz":-420,"elapsed":115376,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Цикл обучения"],"metadata":{"id":"VJUnE0EXBO9h"}},{"cell_type":"markdown","source":["Теперь мы готовы написать полный цикл обучения. После определения прогресс-бара, чтобы следить за ходом обучения, цикл состоит из трех частей:\n","\n","Собственно обучение, которое представляет собой классическую итерацию по train_dataloader, прямой проход по модели, затем обратный проход и шаг оптимизатора.\n","Оценка, в которой мы собираем все значения для start_logits и end_logits перед преобразованием их в массивы NumPy. После завершения цикла оценки мы объединяем все результаты. Обратите внимание, что нам нужно произвести усечение, потому что Accelerator может добавить несколько примеров в конце, чтобы убедиться, что у нас одинаковое количество примеров в каждом процессе.\n","Сохранение и загрузка, где мы сначала сохраняем модель и токенизатор, а затем вызываем repo.push_to_hub(). Как и раньше, мы используем аргумент blocking=False, чтобы указать библиотеке 🤗 Hub на асинхронный процесс push. Таким образом, обучение продолжается нормально, а эта (длинная) инструкция выполняется в фоновом режиме.\n","Вот полный код цикла обучения:"],"metadata":{"id":"cw3gqk3OBTtq"}},{"cell_type":"code","source":["progress_bar = tqdm(range(num_training_steps))\n","\n","for epoch in range(num_train_epochs):\n","    # Обучение\n","    model.train()\n","    for step, batch in enumerate(train_dataloader):\n","        outputs = model(**batch)\n","        loss = outputs.loss\n","        accelerator.backward(loss)\n","\n","        optimizer.step()\n","        lr_scheduler.step()\n","        optimizer.zero_grad()\n","        progress_bar.update(1)\n","\n","    # Оценка\n","    model.eval()\n","    start_logits = []\n","    end_logits = []\n","    accelerator.print(\"Evaluation!\")\n","    for batch in tqdm(eval_dataloader):\n","        with torch.no_grad():\n","            outputs = model(**batch)\n","\n","        start_logits.append(accelerator.gather(outputs.start_logits).cpu().numpy())\n","        end_logits.append(accelerator.gather(outputs.end_logits).cpu().numpy())\n","\n","    start_logits = np.concatenate(start_logits)\n","    end_logits = np.concatenate(end_logits)\n","    start_logits = start_logits[: len(validation_dataset)]\n","    end_logits = end_logits[: len(validation_dataset)]\n","\n","    metrics = compute_metrics(\n","        start_logits, end_logits, validation_dataset, raw_datasets[\"validation\"]\n","    )\n","    print(f\"epoch {epoch}:\", metrics)\n","\n","    # Сохранение и загрузка\n","    accelerator.wait_for_everyone()\n","    unwrapped_model = accelerator.unwrap_model(model)\n","    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n","    if accelerator.is_main_process:\n","        tokenizer.save_pretrained(output_dir)\n","        repo.push_to_hub(\n","            commit_message=f\"Training in progress epoch {epoch}\", blocking=False\n","        )"],"metadata":{"id":"bbd80F9kdBYv","executionInfo":{"status":"aborted","timestamp":1751345917538,"user_tz":-420,"elapsed":115377,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Использование дообученной модели"],"metadata":{"id":"KfmOh-JwBYf9"}},{"cell_type":"markdown","source":["Чтобы использовать ее локально в pipeline, нужно просто указать идентификатор модели:"],"metadata":{"id":"s3U0asSnBb9V"}},{"cell_type":"code","source":["model_checkpoint = \"huggingface-course/bert-finetuned-squad\"\n","question_answerer = pipeline(\"question-answering\", model=model_checkpoint)\n","\n","context = \"\"\"\n","Transformers is backed by the three most popular deep learning libraries — Jax, PyTorch and TensorFlow — with a seamless integration\n","between them. It's straightforward to train your models with one before loading them for inference with the other.\n","\"\"\""],"metadata":{"id":"tZt5-NCvhlpZ","executionInfo":{"status":"aborted","timestamp":1751345917539,"user_tz":-420,"elapsed":115377,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Список вопросов\n","questions = [\n","    \"Which deep learning libraries back Transformers?\",\n","    \"How many popular deep learning libraries support Transformers?\",\n","    \"Can you switch between libraries after training a model?\",\n","    \"Name a library that integrates with Transformers other than PyTorch.\",\n","    \"What is the main advantage of Transformers' library integration?\"\n","]\n","\n","# Запуск модели для каждого вопроса\n","for question in questions:\n","    result = question_answerer(question=question, context=context)\n","    print(f\"Вопрос: {question}\")\n","    print(f\"Ответ: {result['answer']} (score: {result['score']:.4f})\\n\")"],"metadata":{"id":"6XqwUr_Qhmwc","executionInfo":{"status":"aborted","timestamp":1751345917540,"user_tz":-420,"elapsed":115376,"user":{"displayName":"Максим Нестеренко","userId":"13588279963652665930"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Отлично! Наша модель работает так же хорошо, как и модель по умолчанию для этого конвейера!"],"metadata":{"id":"0gbv8vsnBh4l"}}]}